{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Models - ALL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to the 6 feature models, we decided to use all features to run our model.\n",
    "# However, we determined that the results were comparable to the 5 features (oddly, as we are dealing with 12+ times the number of variables)\n",
    "\n",
    "# Because of the extraordinary time spent in compiling the code, we opted to forfeit further analysis of these deep learning models, as they do not have any interpretability nature\n",
    "# due to its characteristics as a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_df = pd.read_csv('./Clean_dataframe/clean_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Final_df.drop('sea_level', axis = 1)\n",
    "y = Final_df['sea_level']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct network\n",
    "model = Sequential()\n",
    "\n",
    "# first layer\n",
    "model.add(Dense(32, input_shape=(67,), activation='relu'))\n",
    "\n",
    "# second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "139/139 [==============================] - 1s 2ms/step - loss: 7913233.5000 - mae: 2625.1140 - val_loss: 7730767.5000 - val_mae: 2590.0635\n",
      "Epoch 2/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 6919425.0000 - mae: 2437.4175 - val_loss: 5685321.0000 - val_mae: 2189.4773\n",
      "Epoch 3/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 3889583.5000 - mae: 1742.9545 - val_loss: 2172343.7500 - val_mae: 1236.8186\n",
      "Epoch 4/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 1250720.3750 - mae: 901.9398 - val_loss: 743327.2500 - val_mae: 702.8821\n",
      "Epoch 5/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 612007.8125 - mae: 639.9565 - val_loss: 552224.8125 - val_mae: 610.7736\n",
      "Epoch 6/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 507669.1562 - mae: 584.6172 - val_loss: 488099.7500 - val_mae: 571.3632\n",
      "Epoch 7/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 454804.1875 - mae: 550.2527 - val_loss: 442917.6562 - val_mae: 540.4407\n",
      "Epoch 8/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 414767.4688 - mae: 522.1645 - val_loss: 406503.6562 - val_mae: 514.6389\n",
      "Epoch 9/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 381946.0625 - mae: 498.1873 - val_loss: 375964.2188 - val_mae: 492.1999\n",
      "Epoch 10/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 354064.5625 - mae: 477.1055 - val_loss: 349389.9062 - val_mae: 471.9771\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_sc, y_train, validation_data=(X_test_sc, y_test), epochs=10, batch_size=512);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3099.7908],\n",
       "       [2437.2837],\n",
       "       [2940.0833],\n",
       "       ...,\n",
       "       [1522.8619],\n",
       "       [2051.1812],\n",
       "       [2586.9224]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 523us/step - loss: 349389.9062 - mae: 471.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[349389.90625, 471.97705078125]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_sc, y_test, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_adv(hidden_neurons = 32, hidden_layers = 5, dropout = 0.5):\n",
    "    # build framework of model using for loop and if statement\n",
    "    model = Sequential()\n",
    "    \n",
    "    # adding number of layers = specified in calling of function\n",
    "    for layer in range(hidden_layers):\n",
    "        if layer == 0:\n",
    "            model.add(Dense(hidden_neurons, activation = 'relu', input_shape = (67,)))\n",
    "            model.add(Dropout(dropout))\n",
    "        else:\n",
    "            model.add(Dense(hidden_neurons, activation = 'relu'))\n",
    "            model.add(Dropout(dropout))\n",
    "    \n",
    "    # out put layer added here, Identity link function used as 'None'\n",
    "    model.add(Dense(1, activation = None))\n",
    "\n",
    "    # using mse as the metric to solve for \n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = KerasRegressor(build_fn = model_fn_adv, batch_size = 512, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_params_deep = {\n",
    "    'hidden_neurons' : [20, 32, 64],\n",
    "    'hidden_layers'  : [2, 3, 5],\n",
    "    'dropout'        : [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'epochs'         : [10, 20, 30, 40, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(nn, param_grid = nn_params_deep, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fbaa11837c0>,\n",
       "             param_grid={'dropout': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         'epochs': [10, 20, 30, 40, 50],\n",
       "                         'hidden_layers': [2, 3, 5],\n",
       "                         'hidden_neurons': [20, 32, 64]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout': 0.2, 'epochs': 40, 'hidden_layers': 5, 'hidden_neurons': 64}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-53445.3125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions \n",
    "preds = gs.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9614068942449125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the R-squared\n",
    "metrics.r2_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LONGITUDE', 'ELEVATION','TMIN', 'TMAX' ,'PRCP','TAVG']\n",
    "X = Final_df[features]\n",
    "y = Final_df['sea_level'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = TimeseriesGenerator(X_train_sc, y_train, length = 3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = TimeseriesGenerator(X_test_sc, y_test, length = 3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_sequences[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(8, input_shape=input_shape, return_sequences=True)) # True if next layer is RNN\n",
    "model.add(GRU(8, return_sequences=False)) # False if next layer is Dense\n",
    "\n",
    "model.add(Dense(4, activation='relu'))\n",
    "\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(train_sequences, validation_data=test_sequences, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1110/1110 [==============================] - 5s 3ms/step - loss: 8092744.0000 - val_loss: 6932919.0000\n",
      "Epoch 2/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 7531867.0000 - val_loss: 6247217.5000\n",
      "Epoch 3/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 6658524.0000 - val_loss: 5353232.5000\n",
      "Epoch 4/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 5622171.0000 - val_loss: 4377156.5000\n",
      "Epoch 5/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 4537966.0000 - val_loss: 3416674.2500\n",
      "Epoch 6/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 3497204.2500 - val_loss: 2552063.0000\n",
      "Epoch 7/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 2582238.2500 - val_loss: 1857080.7500\n",
      "Epoch 8/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 1858629.0000 - val_loss: 1379957.5000\n",
      "Epoch 9/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 1368773.8750 - val_loss: 1133250.7500\n",
      "Epoch 10/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 1109059.2500 - val_loss: 1070938.2500\n",
      "Epoch 11/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 976249.5625 - val_loss: 877303.9375\n",
      "Epoch 12/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 803760.5000 - val_loss: 814941.9375\n",
      "Epoch 13/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 757756.6250 - val_loss: 772826.9375\n",
      "Epoch 14/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 734531.7500 - val_loss: 776723.0000\n",
      "Epoch 15/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 719245.8125 - val_loss: 776201.5000\n",
      "Epoch 16/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 713556.8750 - val_loss: 797687.3750\n",
      "Epoch 17/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 706044.5625 - val_loss: 784940.5625\n",
      "Epoch 18/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 693515.1250 - val_loss: 784236.6250\n"
     ]
    }
   ],
   "source": [
    "# Add early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(GRU(8, input_shape=input_shape, return_sequences=True)) # True if next layer is RNN\n",
    "model2.add(GRU(8, return_sequences=False)) # False if next layer is Dense\n",
    "\n",
    "model2.add(Dense(4, activation='relu'))\n",
    "\n",
    "model2.add(Dense(1))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "es = EarlyStopping(patience = 5)\n",
    "\n",
    "history2 = model2.fit(train_sequences, validation_data=test_sequences, epochs=100, batch_size = 64, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
